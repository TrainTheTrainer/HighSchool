

## Feedback e verifiche come tecniche didattiche

> -----
> ### Programma
> 1. Feedback agli studenti e da parte degli studenti
> 2. Feedback agli studenti
> 3. Valutazione sommativa e formativa
> 4. Questionari di pre-valutazione
> 	- MCQ 
>	- Google Forms
>	- Aspettative (post-it) e verifica delle aspettative
> 5. Feedback da parte degli studenti
> 	- Questionari 
> 	- One-up-one-down
> 	- Cinque dita
> 	- one-good-one-bad (post-it)
> 
> ------

<a name="feedback"></a>
## Feedback agli studenti e da parte degli studenti

Bisogna essere consapevoli della differenza tra il feedback ricevuto dagli studenti e quello dato agli studenti. Entrambi i tipi di feedback sono utili ma hanno finalità diverese.


>### Challenge 1: Che tipo di verifiche conoscete in qualità di studenti?
> 
> * Che tipo di verifiche vi è capitato di fare nella vostra vita di studenti?
> * Qual era la loro finalità? 
> * E' stato utile nel vostro processo di apprendimento? 
> 
> Scrivete almeno un esempio per gruppo e discutetelo con noi

## Feedback agli studenti
Il feedback che viene dato agli studenti è ciò che si fa per aiutare noi stessi - gli insegnanti - e gli studenti per capire se essi hanno effettivamente imparato ciò che abbiamo insegnato loro.

I voti sono un esempio di un tipo di feedback che si usa per informare gli studenti su quale sia stata la loro performance in una verifica o un esame. I voti, da un lato informano i docenti sul processo di apprendimento degli studenti e - dall'altro -  dovrebbero rendere gli studenti consapevoli del loro grado di conoscenza e padronanza di un argomento al momento della verifica o dell'esame.


#### Valutazione sommativa e formativa
Il feedback dato agli studenti può essere di tipo **formativo** or **sommativo** <br>
*Valutazione sommativa*. Un esame o un test alla fine di un corso è un esempio di verifica **sommativa**. Una verifica sommativa ha lo scopo di valutare la performance degli studenti alla fine di una sessione, dello studio di un argomento, di un ciclo di lezioni, di un corso di studi, etc. Si tratta del tipo più frequente di verifica nelle scuole e nelle università e generalmente prevede l'assegnazione di voti. E' il tipo di verifica meno frequente nei corsi di training.

*Valutazione formativa*. Le verifiche formative hanno luogo **durante** l'insegnamento e l'apprendimento. Il loro fine è quello di aiutare sia gli insegnanti che gli studenti a diventare consapevoli di quale debba essere il focus successivo alla verifica.

"Lo scopo della valutazione in aula è quello di migliorare la qualità di apprendimento degli studenti e non di valutare o classificare gli studenti. La valutazione generalmente non è quasi mai valutata ed è quasi sempre anonima (from [From Angelo & Cross, Classroom Assessment techniques, a Handbook for College Teachers](./docs/angelo_and_cross_assessment_techniques.pdf))


La valutazione formativa può essere utilizzata per raccogliere informazioni sugli studenti riguardo alla loro:

- conoscenza precedente
- modelli mentali
- livello di padronanza riguardo ad un argomento
- finalità ed obiettivi
- errori più frequenti

E può aiutare a comprendere: 

- Quali gap nella conoscenza è necessario riempire prima di passare all'argomento successivo
- Se i modelli mentali degli studenti sono corretti
- Se il livello di padronanza è sufficiente in base agli obiettivi e ai risultati di apprendimento del corso
- se gli obiettivi degli studenti sono allineati a quelli del corso
- Che tipo di errori necessitano un'attenzione speciale.

>### Challenge 2: che tipo di verifiche/feedback utilizzate in qualità di insegnanti?
> * Qual è il loro scopo?
> * In che modo fornite feedback agli studenti?
> * In che modo raccogliete il feedback degli studenti?
> * Le vostre tecniche di verifica sono di tipo sommativo o formativo?
> * Scrivete almeno un esempio e discutetelo con gli altri.


Dal [GLOSSARY OF EDUCATION REFORM](edglossary.org/formative-assessment/) (also in [PDF](edglossary.org/formative-assessment/)):

> *La valutazione formativa * si riferisce a una vasta gamma di metodi che gli insegnanti utilizzano per condurre le valutazioni in corso della comprensione degli studenti, le esigenze di apprendimento e progressi accademici durante una lezione, unità, o corso.
>
> Le valutazioni formative aiutano gli insegnanti a identificare quei concetti che gli studenti non riescono a capire, le competenze che stanno avendo difficoltà ad acquisire, o gli standard di apprendimento non ancora raggiunti, al fine di poter apportare delle modifiche alle lezioni, tecniche di insegnamento.
>
>L'obiettivo generale di valutazione formativa è quello di raccogliere informazioni dettagliate che possono essere utilizzate per migliorare le tecniche di insegnamento e l'apprendimento dello studente mentre sta accadendo.
>
>Ciò che rende una valutazione “formativa” non è la progettazione di un test, una tecnica, o una auto-valutazione, di per sé, ma il modo in cui viene utilizzata.
>

Perché una verifica formativa sia utile durante l'insegnamento, deve essere veloce da eseguire e da valutare.
La valutazione formativa può essere utilizzata come una vera e propria strategia didattica e, come tale, una vera opportunità per imparare.

In particolare, essa può essere utilizzata per:

#### 1) Attivare ed esplorare la conoscenza precedente
"Student's prior knowledge can help or hinder learning" <br>(Ambrose et al. (2010) "How learning works", principle 1)

- **strategie per attivare la conoscenza preventiva**
   - fare esempi tratti dalla vita reale
   - porre domande agli studenti in modo tale da stimolare la memoria; questo può aiutarli a utilizzare le conoscenze precedenti al fine di aiutare l'integrazione e la ritenzione di nuove informazioni.
   
- ** strategie per rivelare una accurata ma insufficiente conoscenza preventiva**
    - Fornire un questionario diagnostico. Nel preparare un questionario diagnostico, bisogna essere consapevoli della differenza tra "conoscenza dichiarativa" (sapendo ** cosa ** ) e "conoscenza procedurale (sapendo ** come ** e ** quando applicare procedure diverse, metodi, teorie, ecc.). Un questionario potrebbe essere sufficiente per la valutazione della "conoscenza dichiarativa". Un piccolo esercizio da risolvere può aiutare a valutare la "conoscenza procedurale".

  - Fornire un questionario di autovalutazione. L'autovalutazione può essere un problema, perché gli studenti potrebbero non essere in grado di valutare con precisione le loro capacità. Generalmente, le persone tendono a sovrastimare le proprie conoscenze e competenze. La precisione migliora quando le opzioni di risposta sono chiare e legate a specifici concetti o comportamenti.
   
- **strategie per aiutare gli studenti a riconoscere una inappropriata conoscenza preventiva** 
Se agli studenti viene esplicitamente insegnato quali sono le condizioni e i contesti in cui la conoscenza è applicabile (e inapplicabile), questo può essere di aiuto a evitare l'uso di conoscenze pregresse inappropriate.
  - fare una lista di parole chiave essenziali per l'argomento che stai insegnando e chiedere agli studenti di classificare i termini introdotti in una sessione, al termine della sessione.
  
- **strategie per evidenziare conoscenze pregresse imprecise.** 
Le conoscenze pregresse imprecise possono essere corrette abbastanza facilmente quando si tratta di idee relativamente isolate o di credenze che non sono ancora state incorporate in modelli concettuali più grandi (ad esempio, la convinzione che Plutone è un pianeta). Alcuni tipi di conoscenza preventiva imprecisa - chiamate * convinzioni errate * - sono notevolmente resistenti alla correzione. * Le convinzioni errate * sono modelli o teorie che sono profondamente radicate nel pensiero degli studenti (ad esempio, la nozione che gli oggetti di diverse masse cadono a velocità diverse, 'psicologia popolare' miti come ad esempio che le persone non vedenti hanno un udito più sensibile rispetto alle persone vedenti, o che le stagioni dipendono dalla distanza della Terra dal Sole). 
Le convinzioni errate sono difficili da confutare per una serie di motivi: 1) molte di loro sono stati rafforzati nel corso del tempo e in più contesti; 2) spesso includono sia elementi esatti che inesatti, quindi per gli studenti non è facile riconoscere il loro punto debole; 

#### 3) Esercitare la memoria (fare pratica di accesso alla memoria a lungo termine)
..... (vedi Small Teaching)

#### 4) Stimolare la riflessione e preparare il cervello degli studenti all'apprendimento

#### 5) Evidenziare le debolezze e le difficoltà degli studenti e impostare di conseguenza il ritmo di insegnamento

#### 6) Aiutare gli studenti a capire su che cosa devono concentrarsi

La valutazione formativa può essere fatto in molti modi diversi:

- Fare domande agli studenti e ottenere risposte orali;
- chiedere loro di descrivere la strategia che avrebbero adottato per risolvere un problema;
- Chiedere loro di risolvere un problema in gruppi o singolarmente, ma di fronte alla classe;
- Utilizzo di brainstorming e discussioni;
- Fornire questionari diagnostici;
- Fornire quesiti a scelta multipla (QSM) con "distrattori".


<a name="diagnostic"></a>
### Questionari diagnostici

#### Google forms

Questi tipi di questionari possono essere anonimi o meno. Suggeriamo di usarli in forma anonima.

[Questo (https://docs.google.com/forms/d/1d1yOiNaBdcyGgxaaRqP47b3K06zvYQS0CT8eu0I0d1E/edit#) è un esempio di questionario diagnostico preparato per una sessione di un corso sulle risorse di interazione proteica.

[Qui](https://docs.google.com/forms/d/1d1yOiNaBdcyGgxaaRqP47b3K06zvYQS0CT8eu0I0d1E/viewanalytics) è possibile visualizzare le risposte.

#### Socrative

> Dal sito web Socrative:
> 
>[Socrative](https://www.socrative.com/) è una applicazione che permette di connettersi istantaneamente con gli studenti durante l'apprendimento.
>(È possibile) valutare rapidamente gli studenti con attività o domande ed ottenere informazioni immediate sulla comprensione da parte degli studenti. 

<a name="design"></a>
###  Fornire quesiti a scelta multipla (QSM) con "distrattori" 

> Da [Center for Teaching at the Vanderbilt University](https://cft.vanderbilt.edu/guides-sub-pages/writing-good-multiple-choice-test-questions/).
>
> Un quesito a scelta multipla è costituito da due parti: la domanda  e un elenco e le opzioni di risposta, conosciute come alternative. Le alternative sono costituite da una risposta corretta o migliore alternativa, e da alternative non corrette noto come distrattori.
>
Le domande a scelata multipla, possono essere un metodo efficace ed efficiente per valutare i risultati di apprendimento.I test a risposta multipla hanno diversi vantaggi potenziali:
>

***Versatility***: Multiple choice test items can be written to assess various levels of learning outcomes, from basic recall to application, analysis, and evaluation. Because students are choosing from a set of potential answers, however, there are obvious limits on what can be tested with multiple choice items. **For example, they are not an effective way to test students’ ability to organize thoughts or articulate explanations or creative ideas.**
>
***Reliability***: Reliability is defined as the degree to which a test consistently measures a learning outcome. Multiple choice test items are less susceptible to guessing than true/false questions, making them a more reliable means of assessment. The reliability is enhanced when the number of MC items focused on a single learning objective is increased. In addition, the objective scoring associated with multiple choice test items frees them from problems with scorer inconsistency that can plague scoring of essay questions.
>
***Validity***: Validity is the degree to which a test measures the learning outcomes it purports to measure. Because students can typically answer a multiple choice item much more quickly than an essay question, tests based on multiple choice items can typically focus on a relatively broad representation of course material, thus increasing the validity of the assessment.
>
The key to taking advantage of these strengths, however, is construction of good multiple choice items.

.........

>###Challenge 3: Design a questionnaire
>
>Write three MCQs (in your field of teaching) revealing:
>* a knowledge gap ("what")
>* a weakness in a practical skill ("why, when, how")
>* a misconception


###50 classroom assessment techniques (CATs) by Angelo&Cross

[Here] (./docs/angelo_and_cross_50_cats.pdf) you can find the **50 CATS by Angelo and Cross**. These are fifty assessment techinques grouped by purpose which can be used in teaching and in training. Some of them better apply to university semester courses, or high school classes, wheras some may turn out to be also useful in training courses/sessions. They are fully described and discussed in the book ""Classroom assessment techinques: A handbook for college teachers" (1993) by the same authors.  

**Techniques for Assessing Course-Related Knowledge & Skills**

 - Assessing Prior Knowledge, Recall, and Understanding
 - Assessing Skill in analysis and Critical Thinking
 - Assessing Skill in Synthesis and Creative Thinking
 - Assessing Skill in Problem Solving
 - Assessing Skill in Application and Performance
 
**Techniques for Assessing Learner Attitudes, Values, and Self-Awareness**
 
 - Assessing Students’ Awareness of Their Attitudes and Values
 - Assessing Students’ Self-Awareness as Learners
 - Assessing Course-Related Learning and Study Skills, Strategies, and Behaviors

**Techniques for Assessing Learner Reactions to Instruction**
 
 - Assessing Learner Reactions to Teachers and Teaching
 - Assessing Learner Reactions to Class Activities, Assignments, and Materials

A description of the book written by the authors can be found [here](angelo_and_cross_assessment_techniques.pdf). 

In the following we report the seven assumptions on which the CATs are based and five suggestions to use them fruitfully and effectively: 

>From [Angelo and Cross](angelo_and_cross_assessment_techniques.pdf):
>
> Classroom Assessment is based on seven assumptions:
> 
1. **The quality of student learning is directly, although not exclusively, related to the quality of teaching**. Therefore, one of the most promising ways to improve learning is to improve teaching.
2. **To improve their effectiveness teachers need first to make their goals and objectives explicit** and then to get specific, comprehensible feedback on the extent to which they are achieving those goals and objectives.
3. To improve their learning, **students need to receive approprate and focused feedback early and often**; they also need to learn how to assess their own learning.
4. The type of assessment most likely to improve teaching and learning is that conducted by faculty to answer questions they themselves have formulated in response to issues or problems in their own teaching.
5. **Systematic inquiry and intellectual challenge** are powerful sources of motivation, growth, and renewal for college teachers, and Classroom Assessment can provide such challenge.
6. Classroom Assessment does not require specialized training; it can be carried out by dedicated teachers from all disciplines.
7. By collaborating with colleagues and actively involving students in Classroom Assessment efforts, faculty (and students) enhance learning and personal satisfaction.
>
> Five suggestions for a successful start:
1. If a Classroom Assessment Techniques does not appeal to your intuition and professional judgement as a teacher, don't use it.
2. Don't make Classroom Assessment into a self-inflicted chore or burden.
3. Don't ask your students to use any Classroom Assessment Technique you haven't previously tried on yourself.
4. Allow for more time than you think you will need to carry out and respond to the assessment.
5. Make sure to "close the loop." Let students know what you learn from their feedback and how you and they can use that information to improve learning.


<a name="self"></a>
###Self-assessment, self-confidence and usage independence

In active learning environments, learners are so involved in the learning process that they often loose consciousness about their accumulated knowledge and its level of operational value. Learning by doing catches them in the process, so they often forget about assessing it.

In good quality training, instructors make efforts to keep the interaction loop closed. As facilitators, they can give steering contributions to this buil-up.

At carefully chosen times, it may be useful to intervene and stimulate self assessment (see how to, under instant feedback below). Self assessment helps to regain such consciousness. Learners verify that they can do things that they could not do by themselves before, or at least that the need for external aid is lowering. This can be seen as a work-out process towards gaining independence or mastery in a subject matter. The conscious learner feels "empowered". It is up to the instructor to moderate and keep this empowerment within reasonable limits. Learners that are not feeling empowered often find it by comparing their experience with their peers. Dialogues between learners will naturally occur, but can also be stimulated by reflective exercises (such as in Software and Data Carpentry). The instructor will learn to adapt the level of intervention to each situation, keeping in mind that the learner is the focus of the learning process, and that the instructor/learner relationship is the cornerstone of learning as a stimulated human activity.

The recently empowered learner will naturally want to test new knowledge by using it in different contexts. Simple observation our experience as human beings is that if our knowledge in a subject is solid, it may also work in different settings or environments. This is good as a positive test, but the novice learner may fail in several aspects, such as overlooking assumptions, for example. In a closed loop interaction that is desired in a training environment, this can be seen as experimentation, subject to the exact same rules as any experimental work. The instructor can help to steer this process, stimulate the testing when he sees value in it, helping to highlight and avoid the pitfalls, validate the outcomes, etc. In this way he is directly stimulating critical thinking.

[a note regarding its usage in training quality assessment]
Usage independence gained in active learning environments is a measure of training effectiveness. It can be usefully associated with each learning instance. In particular, a well designed training exercise with a well defined learning outcome, can be seen as a gauge for measuring effectiveness in a focused way. In a training instance (a course, a programme) if this technique is applied systematically, overall quantitative data about training effectively may emerge. It will need to be subject to validation via independent testing, confrontation with other assessment methodologies and ultimately subject to a critical appraisal of its value.

Quotes form "Peer Instruction, Getting students to think in class" by Erik Mazur , pdf available [here](http://mazur.harvard.edu/sentFiles/Mazur_274537.pdf)

".. while listening is largely a passive activity, reading more easily engages the mind and it allows more time for the imagination to explore questions." 

"the first exposure to new material comes from reading printed material before the lecture reading." 


to be continued .... SEE QUESTIONNAIRE [here](./doc/peer-instruction-Mazur.pdf)


##Feedback from learners

Feedback from learners is aimed at:

- assessing learner reactions to teachers and teaching thus providing context-specific feedback that can improve teaching within a particular course;
- assessing learner reactions to class activities, assignments, and materials thus giving instructors information that will help them improve their course materials and assignments;
- assessing learner reactions course organisational aspects, thus providing the organiser information that will help him or her to improve the course organisation.

<a name="assessment"></a>
### Assessment of training quality, participant and instructor performance

Examples of feedback questionnaires:

1) This is the type of questionnaire we developed for ELIXIR Italy courses:

[Feedback questionnaire](https://docs.google.com/forms/d/101Z1pufbmWTGN-P_EgHYaeXN1g0uSRQiGDJeFe_NBEg/edit#) for the ELIXIR Italy course on "NGS for evolutionary biologists: from basic scripting to variant calling" (Rome, 23-27 November 2015)

We adapt it to each new course.

2) This is the type of questionnaire used to assess the quality of bioinformatics courses organised and delivered by the Gulbenkian Training Programme in Bioinformatics at the Instituto Gulbenkian de Ciência:

[Feedback questionnaire](./docs/Questionnaire.pdf) for the course on "Bioinformatics using Python for Biomedical Researchers" (Oeiras, PT July 11th – July 15th 2016)

<a name="systematic"></a>
### Systematic feedback

In a training course, getting feedback at the end of the event is necessary, as the participants may (should) have developed encompassing, integrated views. However, it is vastly insufficient. Questioning participants frequently during training provision is rich with information and has very interesting effects. But when should this happen? And how can it be induced so that, as a drug, has as many positive effects  and as low adverse effects as possible?

When? Ideally at natural breakpoints such as ending an exercise, shifting to a different subject and right after a wrap-up session.

How? It should be very focused and expedite in execution. The instructor should think of a clearly stated question that has a binary (Yes/no) or garaded (0-5) response. Ideally the isntructor should write the question and display it, ensuring that everybody knows what the question is at the same time and is aware of what the answering method is. Then, the isntructor collects the answers and records trhem in a tally. 

This is **Instant Feedback**. 

Several methods have been tested, some of the using technology (Clickers, Socrative, Learning Catalytics) or not (the fist of five method). The choice is made according to the availability of the means and how engaging the audience finds it.

---
>###Fist or Five Feedback
>
>by Allegra Via, Kristian Rother and Pedro Fernandes
>From: [Academis by Kristian Rother](http://www.academis.sites.djangoeurope.com/blog/posts/recipe-fist-or-five/).
>
>
>How well was your explanation understood? How useful was an exercise? Is your class enthusiastic or frustrated? During a one-week programming course at IGC, Portugal,  we asked after each training module:

>"How much did you learn during the lesson? Please show one to five fingers. Raise your hands!"
>
>Then we counted how often each number of fingers occurred. This way, the trainees felt more encouraged to provide critical feedback than if you would simply ask:

>"did you understand it or not?"

>Not necessarily do trainees utilize all five fingers. Our course participant Patricia commented:

>"It is a good feedback and it is immediate. Although I feel sometimes a little bit shy to express my opinion."

>The method needs seconds to execute and no preparation, which is a plus for the teacher. But trainees benefit as well. Our course participant Rita commented:

>"I like it because it makes me think. It forces me to review and figure out whether I understood the subject or not and how much. It also shows you are interested."

>This feedback is not an objective control of students' knowledge; it gives rather an indication of how confident they feel at a given point. You can try to suggest examples what a zero or five means, as in the linked article. The fist or five technique has also been recommended as a voting procedure to reach consensus in group discussions. You may test the method after giving a presentation to evaluate yourself.

>The numbers we accumulated over more than a dozen sessions using one consistent method helped us to keep the course on track. The counting itself needed a bit of exercise to do it quickly. When we used the Fist or Five technique for the first time in 2012 with a group of 20 people, we asked for each number from zero to five separately This took a bit longer. For us, the main value of the Fist or Five technique is that it is easy to execute, it is quantitative, it is not stressful, it is immediate and can be repeated many times during a course. We hope you will see lots of 'high fives' in your next course!
>
---

### Carpentry assessing practices

Notice that the Carpentry teaching practices quoted in [session 2](./TtT-session2.md) - Sticky notes; Minutes cards; One-up, one-down - are forms of Instant Feedback.

### Instant Feedback: benefits worth noticing 

* For the LEARNER. Carefully implemented instant feedback obliges the learner to introspect, to answer himself first (do I really know this? How easy ist it for me to do this by myself?). With this, it becomes clear that he is made aware of his own progress and this is the smartes way to gain self-confidence. When questioned at the end-of the course questionnaire, he is much more able to make encompassing self assessments
* For the INSTRUCTOR. Multiple ways of checking if what has just been done was effective, as a result of the quality of the question. Useful assessment of the quality of the materials and the performance of the instructor. A way of identifying learners that may be dragging behind and may need more attention. A way of identifying learners that are getting ahead o the others in the group, and can become more active, receive harder assignments, help their colleagues, etc. A way to judge wheather the pace of training delivery is correctly chosen for the audience.

<a name="short"></a>
### (Short and long term) Post-course feedback

Long term assessments are rather difficult. First becaulse learners move and become more diffuicult to cantact with. Secondly because they forget, as all of us do. In this case they forget what worked for them as hidden details. Those may matter because what we are looking for, here, is the aseesment of impacts that endure.

Interviewing former course participants would be a possibility but it requires a lot of time. Sending them short questions by e-mail has worked  with a yeald of about 30%, so unless you are tarining at least several hundreds of people it is likely that you end-up with a very small number of answers. Currently we see some home in the usage of social networks to collect valuable data.

Critical appraisals often happen is casual conversations. One should take notes to record them.

Example: Pedro Fernandes, Pooja Jain, Catarina Moita Training Experimental Biologists
in Bioinformatics, Adv Bioinformatics. 2012;2012:672749. doi:
10.1155/2012/672749. Epub 2012 Jan 31. (Open Access)

####Training Evaluation

There are several methods that can be used to evaluate training. One of the most referenced methods comes from Donald Kirpatrick (1924-2014).

####The Kirkpatrick Model

- Level 1: Reaction <br>
The degree to which participants find the training favorable, engaging and relevant to their jobs

- Level 2: Learning <br>
The degree to which participants acquire the intended knowledge, skills, attitude, confidence and commitment based on their participation in the training

- Level 3: Behavior <br>
The degree to which participants apply what they learned during training when they are back on the job

- Level 4: Results <br>
The degree to which targeted outcomes occur as a result of the training and the support and accountability package

This model has been revised and expanded several times, see for example:

http://www.kirkpatrickpartners.com/OurPhilosophy/TheNewWorldKirkpatrickModel/tabid/303/Default.aspx

Applying the Kirkpatrick model and its variants is not easy. One needs to be very careful in checking pre-requisites, assumptions and options in the measurement methods.

The evaluation of training efficiency is a difficult subject. There is an obvious need to standardise to allow for the comparison of observations.

You may like to read an article about applying Kirkpatrick's methods. https://www.mindtools.com/pages/article/kirkpatrick.htm

### Condivisione di griglie di valutazione (mastery rubrics) con gli studenti

### Condivisione e accettazione condivisa di regole

### Peer instruction
https://www.youtube.com/watch?t=1&v=2LbuoxAy56o
https://www.youtube.com/watch?v=Z9orbxoRofI
